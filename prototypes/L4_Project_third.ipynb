{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansfarooq7/l4-project/blob/main/prototypes/L4_Project_third.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07rSZucTmc6P"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuvW3fmor6Tu",
        "outputId": "27d58c0e-3f0c-4edb-dca2-5bf95364c39d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pronouncing in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: cmudict>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pronouncing) (1.0.2)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: syllables in /usr/local/lib/python3.7/dist-packages (1.0.3)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.7/dist-packages (2.7.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.19.5)\n",
            "Requirement already satisfied: analytics-python in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.7/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from gradio) (3.14.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.7/dist-packages (from gradio) (0.0.5)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (from gradio) (0.73.0)\n",
            "Requirement already satisfied: markdown2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.4.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.7/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.7/dist-packages (from gradio) (0.17.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (21.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.7.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (3.10.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.0.11)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (0.13.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.15.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.6)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Requirement already satisfied: backoff==1.10.0 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2021.10.8)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi->gradio) (1.9.0)\n",
            "Requirement already satisfied: starlette==0.17.1 in /usr/local/lib/python3.7/dist-packages (from fastapi->gradio) (0.17.1)\n",
            "Requirement already satisfied: anyio<4,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.17.1->fastapi->gradio) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.0.0->starlette==0.17.1->fastapi->gradio) (1.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2018.9)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (36.0.1)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (3.2.0)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (1.5.0)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Requirement already satisfied: asgiref>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (3.5.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (0.13.0)\n",
            "Requirement already satisfied: aitextgen in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: transformers>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (4.16.2)\n",
            "Requirement already satisfied: pytorch-lightning>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (1.5.9)\n",
            "Requirement already satisfied: fire>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (0.4.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (1.10.0+cu111)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.15.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (1.19.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (3.10.0.2)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (21.3)\n",
            "Requirement already satisfied: setuptools==59.5.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (59.5.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (2022.1.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.62.3)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.7.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (0.18.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.7)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.43.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.2.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (0.0.47)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (0.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (0.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.7.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.11)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (6.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.5.1->aitextgen) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.5.1->aitextgen) (7.1.2)\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install pronouncing\n",
        "!pip install wikipedia\n",
        "!pip install syllables\n",
        "!pip install aitextgen\n",
        "\n",
        "from transformers import RobertaTokenizer, RobertaForMaskedLM, pipeline, GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "import pronouncing\n",
        "import wikipedia\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "import syllables\n",
        "nltk.download('cmudict')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "masked_model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
        "\n",
        "causal_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "causal_model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=causal_tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "lH95CWCU1bY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "603f635f-7d59-4300-891f-56cded91a9f7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AegKaJ99lPKQ"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "wAtoq8MglRU5"
      },
      "outputs": [],
      "source": [
        "frequent_words = set()\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    \"\"\"\n",
        "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
        "    installed).\n",
        "\n",
        "    Args:\n",
        "        seed (:obj:`int`): The seed to set.\n",
        "    \"\"\"\n",
        "    #random.seed(seed)\n",
        "    #np.random.seed(seed)\n",
        "    #if is_torch_available():\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "        # ^^ safe to call this function even if cuda is not available\n",
        "    #if is_tf_available():\n",
        "        #tf.random.set_seed(seed)\n",
        "        \n",
        "with open(\"wordFrequency.txt\", 'r') as f:\n",
        "    line = f.readline()\n",
        "    while line != '':  # The EOF char is an empty string\n",
        "        frequent_words.add(line.strip())\n",
        "        line = f.readline()\n",
        "\n",
        "def filter_rhymes(word):\n",
        "    filter_list = ['to', 'on', 'has', 'but', 'the', 'in', 'and', 'a', 'aitch', 'angst', 'arugula', 'beige', 'blitzed', 'boing', 'bombed', 'cairn', 'chaos', 'chocolate', 'circle', 'circus', 'cleansed', 'coif', 'cusp', 'doth', 'else', 'eth', 'fiends', 'film', 'flange', 'fourths', 'grilse', 'gulf', 'kiln', 'loge', 'midst', 'month', 'music', 'neutron', 'ninja', 'oblige', 'oink', 'opus', 'orange', 'pint', 'plagued', 'plankton', 'plinth', 'poem', 'poet', 'purple', 'quaich', 'rhythm', 'rouged', 'silver', 'siren', 'soldier', 'sylph', 'thesp', 'toilet', 'torsk', 'tufts', 'waltzed', 'wasp', 'wharves', 'width', 'woman', 'yttrium'] \n",
        "    if word in filter_list:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "def get_rhymes(inp, level):\n",
        "    entries = nltk.corpus.cmudict.entries()\n",
        "    syllables = [(word, syl) for word, syl in entries if word == inp]\n",
        "    rhymes = []\n",
        "    filtered_rhymes = set()\n",
        "    for (word, syllable) in syllables:\n",
        "        rhymes += [word for word, pron in entries if pron[-level:] == syllable[-level:]]\n",
        "    \n",
        "    for word in rhymes:\n",
        "        if (word in frequent_words) and (word != inp):\n",
        "            filtered_rhymes.add(word)\n",
        "    return filtered_rhymes\n",
        "\n",
        "def get_inputs_length(input):\n",
        "    input_ids = causal_tokenizer(input)['input_ids']\n",
        "    return len(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZN0Cwg0mj6g"
      },
      "source": [
        "## RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "AIRsE899r-53"
      },
      "outputs": [],
      "source": [
        "set_seed(0)\n",
        "    \n",
        "def get_prediction(sent):\n",
        "    \n",
        "    token_ids = masked_tokenizer.encode(sent, return_tensors='pt')\n",
        "    masked_position = (token_ids.squeeze() == masked_tokenizer.mask_token_id).nonzero()\n",
        "    masked_pos = [mask.item() for mask in masked_position ]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = masked_model(token_ids)\n",
        "\n",
        "    last_hidden_state = output[0].squeeze()\n",
        "\n",
        "    list_of_list =[]\n",
        "    for index,mask_index in enumerate(masked_pos):\n",
        "        words = []\n",
        "        while not words:\n",
        "            mask_hidden_state = last_hidden_state[mask_index]\n",
        "            idx = torch.topk(mask_hidden_state, k=5, dim=0)[1]\n",
        "            for i in idx:\n",
        "                word = masked_tokenizer.decode(i.item()).strip()\n",
        "                if (remove_punctuation(word) != \"\") and (word != '</s>'):\n",
        "                    words.append(word)\n",
        "            #words = [masked_tokenizer.decode(i.item()).strip() for i in idx]\n",
        "        list_of_list.append(words)\n",
        "        print(f\"Mask {index+1} Guesses: {words}\")\n",
        "    \n",
        "    best_guess = \"\"\n",
        "    for j in list_of_list:\n",
        "        best_guess = best_guess+\" \"+j[0]\n",
        "        \n",
        "    return best_guess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H10sWlKFltm0",
        "outputId": "25cd9567-d724-4136-d3d4-75cfa6750399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: Manchester United ___ ___ ___ team\n",
            "Original Sentence replaced with mask: Manchester United <mask> <mask> <mask> team.\n",
            "\n",
            "\n",
            "Mask 1 Guesses: [\"'s\", 'vs', 'and', 'as']\n",
            "Mask 2 Guesses: ['the', 'their', 'a', 'The']\n",
            "Mask 3 Guesses: ['first', 'football', 'best', 'national', 'B']\n",
            "\n",
            "Best guess for fill in the blanks:  's the first\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Manchester United ___ ___ ___ team\"\n",
        "print(f\"Original Sentence: {sentence}\")\n",
        "if sentence[-1] != \".\":\n",
        "    sentence = sentence.replace(\"___\",\"<mask>\") + \".\"\n",
        "else:\n",
        "    sentence = sentence.replace(\"___\",\"<mask>\")\n",
        "print(f\"Original Sentence replaced with mask: {sentence}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "predicted_blanks = get_prediction(sentence)\n",
        "print(f\"\\nBest guess for fill in the blanks: {predicted_blanks}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp8L4cJwmoXP"
      },
      "source": [
        "## GPT-2 + RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "o2Rtm86GKwbg"
      },
      "outputs": [],
      "source": [
        "text_generation = pipeline(\"text-generation\", model=causal_model, tokenizer=causal_tokenizer)\n",
        "from aitextgen import aitextgen\n",
        "\n",
        "# Without any parameters, aitextgen() will download, cache, and load the 124M GPT-2 \"small\" model\n",
        "ai = aitextgen()\n",
        "\n",
        "\n",
        "def get_line(prompt, inputs_len):\n",
        "    line = ai.generate_one(prompt=prompt + \".\", max_length=inputs_len + 7)[len(prompt)+2:]\n",
        "    return line\n",
        "\n",
        "def get_rhyming_line(prompt, rhyming_word, inputs_len):\n",
        "    gpt2_sentence = ai.generate_one(prompt=prompt + \".\", max_length=inputs_len + 4)[len(prompt)+2:]\n",
        "    print(f\"\\nGetting rhyming line starting with '{gpt2_sentence}' and ending with rhyming word '{rhyming_word}'\")\n",
        "    sentence = gpt2_sentence + \" ___ ___ ___ \" + rhyming_word\n",
        "    print(f\"Original Sentence: {sentence}\")\n",
        "    if sentence[-1] != \".\":\n",
        "        sentence = sentence.replace(\"___\",\"<mask>\") + \".\"\n",
        "    else:\n",
        "        sentence = sentence.replace(\"___\",\"<mask>\")\n",
        "    print(f\"Original Sentence replaced with mask: {sentence}\")\n",
        "    print(\"\\n\")\n",
        " \n",
        "    predicted_blanks = get_prediction(sentence)\n",
        "    print(f\"\\nBest guess for fill in the blanks: {predicted_blanks}\")\n",
        "    final_sentence = gpt2_sentence + predicted_blanks + \" \" + rhyming_word\n",
        "    print(f\"Final Sentence: {final_sentence}\")\n",
        "    return final_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Bqq_Zemsf3"
      },
      "source": [
        "## Limerick generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "dDeTSyiisEJJ"
      },
      "outputs": [],
      "source": [
        "def generate(topic):\n",
        "\n",
        "    limericks = []\n",
        "\n",
        "    topic_summary = remove_punctuation(wikipedia.summary(topic))\n",
        "    word_list = topic_summary.split()\n",
        "    topic_summary_len = len(topic_summary)\n",
        "    no_of_words = len(word_list)\n",
        "    inputs_len = get_inputs_length(topic_summary)\n",
        "    print(f\"Topic Summary: {topic_summary}\")\n",
        "    print(f\"Topic Summary Length: {topic_summary_len}\")\n",
        "    print(f\"No of Words in Summary: {no_of_words}\")\n",
        "    print(f\"Length of Input IDs: {inputs_len}\")           \n",
        "\n",
        "    for i in range(1):\n",
        "        print(f\"\\nGenerating limerick {i+1}\")\n",
        "        rhyming_words_125 = []\n",
        "        while len(rhyming_words_125) < 3 or valid_rhyme == False or len(first_line) == 0:\n",
        "            first_line = get_line(topic_summary, inputs_len)\n",
        "            if first_line:\n",
        "                end_word = remove_punctuation(first_line.split()[-1])\n",
        "                valid_rhyme = filter_rhymes(end_word)\n",
        "                if valid_rhyme:\n",
        "                    print(f\"\\nFirst Line: {first_line}\")\n",
        "                    rhyming_words_125 = list(get_rhymes(end_word, 3))\n",
        "                    print(f\"Rhyming words for '{end_word}' are {rhyming_words_125}\")\n",
        "                    limerick = first_line + \"\\n\"\n",
        "\n",
        "        rhyming_word = rhyming_words_125[0]\n",
        "        second_line = get_rhyming_line(topic_summary, rhyming_word, inputs_len)\n",
        "        print(f\"\\nSecond Line: {second_line}\")\n",
        "        limerick += second_line + \"\\n\"\n",
        "\n",
        "        rhyming_words_34 = []\n",
        "        while len(rhyming_words_34) < 2 or valid_rhyme == False or len(third_line) == 0:\n",
        "            third_line = get_line(topic_summary, inputs_len)\n",
        "            if third_line:\n",
        "                print(f\"\\nThird Line: {third_line}\")\n",
        "                end_word = remove_punctuation(third_line.split()[-1])\n",
        "                valid_rhyme = filter_rhymes(end_word)\n",
        "                print(f\"Does '{end_word}'' have valid rhymes: {valid_rhyme}\")\n",
        "                rhyming_words_34 = list(get_rhymes(end_word, 3))\n",
        "                print(f\"Rhyming words for '{end_word}' are {rhyming_words_34}\")\n",
        "                if valid_rhyme and len(rhyming_words_34) > 1:\n",
        "                    limerick += third_line + \"\\n\"\n",
        "\n",
        "        rhyming_word = rhyming_words_34[0]\n",
        "        fourth_line = get_rhyming_line(topic_summary, rhyming_word, inputs_len)\n",
        "        print(f\"\\nFourth Line: {fourth_line}\")\n",
        "        limerick += fourth_line + \"\\n\"\n",
        "\n",
        "        rhyming_word = rhyming_words_125[1]\n",
        "        fifth_line = get_rhyming_line(topic_summary, rhyming_word, inputs_len)\n",
        "        print(f\"\\nFifth Line: {fifth_line}\")\n",
        "        limerick += fifth_line + \"\\n\"\n",
        "\n",
        "        limericks.append(limerick)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    output = f\"Generated {len(limericks)} limericks: \\n\"\n",
        "\n",
        "    print(f\"Generated {len(limericks)} limericks: \\n\")\n",
        "    for limerick in limericks:\n",
        "        print(limerick)\n",
        "        output += \"\\n\" + limerick\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic = input(\"Enter topic: \")\n",
        "generate(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M7LWSO-mVaJ6",
        "outputId": "91a49980-b81c-4b3d-b27f-46c6324d3011"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter topic: manchester united\n",
            "Topic Summary: Manchester United Football Club is a professional football club based in Old Trafford Greater Manchester England that competes in the Premier League the top flight of English football Nicknamed the Red Devils the club was founded as Newton Heath LYR Football Club in 1878 but changed its name to Manchester United in 1902 The club moved from Newton Heath to its current stadium Old Trafford in 1910\n",
            "Manchester United have won the most trophies in English club football including a record 20 League titles 12 FA Cups five League Cups and a record 21 FA Community Shields They have won the European CupUEFA Champions League three times and the UEFA Europa League the UEFA Cup Winners Cup the UEFA Super Cup the Intercontinental Cup and the FIFA Club World Cup once each In 1968 under the management of Matt Busby 10 years after eight of the clubs players were killed in the Munich air disaster they became the first English club to win the European Cup Alex Ferguson is the clubs longestserving and most successful manager winning 38 trophies including 13 league titles 5 FA Cups and 2 UEFA Champions League titles between 1986 and 2013 In the 199899 season under Ferguson the club became the first in the history of English football to achieve the European treble of the Premier League FA Cup and UEFA Champions League In winning the UEFA Europa League under José Mourinho in 201617 they also became one of five clubs to have won the original three main UEFA club competitions the Champions League Europa League and Cup Winners Cup\n",
            "Manchester United is one of the most widely supported football clubs in the world and has rivalries with Liverpool Manchester City Arsenal and Leeds United Manchester United was the highestearning football club in the world for 201617 with an annual revenue of 6763 million and the worlds third most valuable football club in 2019 valued at 315 billion 381 billion After being floated on the London Stock Exchange in 1991 the club was taken private in 2005 after a purchase by Malcolm Glazer valued at almost 800 million of which over 500 million of borrowed money became the clubs debt From 2012 some shares of the club were listed on the New York Stock Exchange although the Glazer family retains overall ownership and control of the club\n",
            "Topic Summary Length: 2271\n",
            "No of Words in Summary: 392\n",
            "Length of Input IDs: 414\n",
            "\n",
            "Generating limerick 1\n",
            "\n",
            "First Line: Manchester United has been purchased by\n",
            "Rhyming words for 'by' are ['buy', 'bye']\n",
            "\n",
            "First Line: Manchester United Football Club is\n",
            "Rhyming words for 'is' are []\n",
            "\n",
            "First Line: Manchester United were the first\n",
            "Rhyming words for 'first' are ['worst', 'burst']\n",
            "\n",
            "First Line: Manchester United Football Club is\n",
            "Rhyming words for 'is' are []\n",
            "\n",
            "First Line: Manchester United's current owners\n",
            "Rhyming words for 'owners' are ['prisoners', 'centers', 'partners']\n",
            "\n",
            "Getting rhyming line starting with 'Manchester United' and ending with rhyming word 'prisoners'\n",
            "Original Sentence: Manchester United ___ ___ ___ prisoners\n",
            "Original Sentence replaced with mask: Manchester United <mask> <mask> <mask> prisoners.\n",
            "\n",
            "\n",
            "Mask 1 Guesses: ['have', 'are', 'had', 'were', 'and']\n",
            "Mask 2 Guesses: ['released', 'the', 'two', 'seven', 'four']\n",
            "Mask 3 Guesses: ['political', '10', 'the', 'released', 'Palestinian']\n",
            "\n",
            "Best guess for fill in the blanks:  have released political\n",
            "Final Sentence: Manchester United have released political prisoners\n",
            "\n",
            "Second Line: Manchester United have released political prisoners\n",
            "\n",
            "Third Line: Manchester United have won the\n",
            "Does 'the'' have valid rhymes: False\n",
            "Rhyming words for 'the' are []\n",
            "\n",
            "Third Line: The Glazer family has been\n",
            "Does 'been'' have valid rhymes: True\n",
            "Rhyming words for 'been' are ['robin', 'cabin', 'carbon', 'urban', 'bin']\n",
            "\n",
            "Getting rhyming line starting with 'Manchester United' and ending with rhyming word 'robin'\n",
            "Original Sentence: Manchester United ___ ___ ___ robin\n",
            "Original Sentence replaced with mask: Manchester United <mask> <mask> <mask> robin.\n",
            "\n",
            "\n",
            "Mask 1 Guesses: ['win', 'won', 'vs', 'beat', 'v']\n",
            "Mask 2 Guesses: ['a', 'the', 'to', 'at', 'by']\n",
            "Mask 3 Guesses: ['round', 'round', 'Round', 'dead', 'Round']\n",
            "\n",
            "Best guess for fill in the blanks:  win a round\n",
            "Final Sentence: Manchester United win a round robin\n",
            "\n",
            "Fourth Line: Manchester United win a round robin\n",
            "\n",
            "Getting rhyming line starting with 'From 2012 the' and ending with rhyming word 'centers'\n",
            "Original Sentence: From 2012 the ___ ___ ___ centers\n",
            "Original Sentence replaced with mask: From 2012 the <mask> <mask> <mask> centers.\n",
            "\n",
            "\n",
            "Mask 1 Guesses: ['government', 'country', 'city', 'following', 'Netherlands']\n",
            "Mask 2 Guesses: ['opened', 'added', 'closed', 'established', 'has']\n",
            "Mask 3 Guesses: ['four', 'two', 'six', 'three', 'five']\n",
            "\n",
            "Best guess for fill in the blanks:  government opened four\n",
            "Final Sentence: From 2012 the government opened four centers\n",
            "\n",
            "Fifth Line: From 2012 the government opened four centers\n",
            "\n",
            "\n",
            "Generated 1 limericks: \n",
            "\n",
            "Manchester United's current owners\n",
            "Manchester United have released political prisoners\n",
            "The Glazer family has been\n",
            "Manchester United win a round robin\n",
            "From 2012 the government opened four centers\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Generated 1 limericks: \\n\\nManchester United's current owners\\nManchester United have released political prisoners\\nThe Glazer family has been\\nManchester United win a round robin\\nFrom 2012 the government opened four centers\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "L4 Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}