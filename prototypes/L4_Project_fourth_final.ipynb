{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansfarooq7/l4-project/blob/main/prototypes/L4_Project_fourth_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07rSZucTmc6P"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuvW3fmor6Tu",
        "outputId": "dd127864-249a-4b2a-d020-14c59c6b813e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.7/dist-packages (2.8.13)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (from gradio) (0.75.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.7/dist-packages (from gradio) (2.10.3)\n",
            "Requirement already satisfied: analytics-python in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from gradio) (3.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.7/dist-packages (from gradio) (0.17.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.7/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.7/dist-packages (from gradio) (3.6.7)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.7/dist-packages (from gradio) (0.0.5)\n",
            "Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.7/dist-packages (from gradio) (2.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (3.10.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Requirement already satisfied: backoff==1.10.0 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.10.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi->gradio) (1.9.0)\n",
            "Requirement already satisfied: starlette==0.17.1 in /usr/local/lib/python3.7/dist-packages (from fastapi->gradio) (0.17.1)\n",
            "Requirement already satisfied: anyio<4,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.17.1->fastapi->gradio) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.0.0->starlette==0.17.1->fastapi->gradio) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.0)\n",
            "Requirement already satisfied: linkify-it-py~=1.0 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.7/dist-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2018.9)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (3.2.0)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (1.5.0)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (36.0.2)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: asgiref>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (3.5.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (0.13.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Install packages not pre-installed\n",
        "!pip install transformers\n",
        "!pip install wikipedia\n",
        "!pip install gradio\n",
        "\n",
        "# Import required packages\n",
        "from transformers import RobertaTokenizer, RobertaForMaskedLM, GPT2Tokenizer, GPT2LMHeadModel, pipeline\n",
        "import torch\n",
        "import wikipedia\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "import gradio as gr\n",
        "nltk.download('cmudict')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lH95CWCU1bY_"
      },
      "outputs": [],
      "source": [
        "# Use the RoBERTa model from HuggingFace for masked language modelling\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta_model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
        "\n",
        "# Use the GPT-2 from HuggingFace for causal language modelling\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=gpt2_tokenizer.eos_token_id)\n",
        "\n",
        "# Initialise a text generation pipeline using HuggingFace Transformers and the pre-trained GPT-2 model\n",
        "gpt2_pipeline = pipeline('text-generation', model=gpt2_model, tokenizer=gpt2_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AegKaJ99lPKQ"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wAtoq8MglRU5"
      },
      "outputs": [],
      "source": [
        "# Hold all the words in wordFrequency.txt in a Python set\n",
        "# This word frequency list is the top 5000 word forms taken from: \n",
        "# https://www.wordfrequency.info/samples.asp\n",
        "frequent_words = set()\n",
        "with open(\"wordFrequency.txt\", 'r') as f:\n",
        "    line = f.readline()\n",
        "    while line != '':  # The EOF char is an empty string\n",
        "        frequent_words.add(line.strip())\n",
        "        line = f.readline()\n",
        "\n",
        "# Used alongside the word frequency list to filter out problematic words for rhyming\n",
        "def filter_rhymes(word):\n",
        "    filter_list = ['an', 'to', 'on', 'has', 'but', 'the', 'in', 'and', 'a', 'are', 'or', 'its', 'it''s'] \n",
        "    if word in filter_list:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "# Used to remove any punctuation and new line characters from generated text\n",
        "def remove_punctuation(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return text.strip()\n",
        "\n",
        "# Used to find rhymes to a given word using NLTK\n",
        "# where inp is a word and level means how good the rhyme should be.\n",
        "# Adapted from the following Stack Overflow answer:\n",
        "# https://stackoverflow.com/a/25714769/18559178\n",
        "def get_rhymes(inp, level):\n",
        "    entries = nltk.corpus.cmudict.entries()\n",
        "    syllables = [(word, syl) for word, syl in entries if word == inp]\n",
        "    rhymes = []\n",
        "    filtered_rhymes = set()\n",
        "    for (word, syllable) in syllables:\n",
        "        rhymes += [word for word, pron in entries if pron[-level:] == syllable[-level:]]\n",
        "    \n",
        "    for word in rhymes:\n",
        "        if (word in frequent_words) and (word != inp):\n",
        "            filtered_rhymes.add(word)\n",
        "    return filtered_rhymes\n",
        "\n",
        "# Used to get the length of the topic summary, to then determine max length for\n",
        "# the text generation pipeline\n",
        "def get_inputs_length(input):\n",
        "    input_ids = gpt2_tokenizer(input)['input_ids']\n",
        "    return len(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZN0Cwg0mj6g"
      },
      "source": [
        "## RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AIRsE899r-53"
      },
      "outputs": [],
      "source": [
        "# Sized Fill-in-the-blank or Multi Mask filling with RoBERTa and Huggingface Transformers\n",
        "# Used to fill in the blank words between the starting words of each line\n",
        "# generated by GPT-2 and the end rhyming word\n",
        "# Code adapted from the following Medium article:\n",
        "# https://ramsrigoutham.medium.com/sized-fill-in-the-blank-or-multi-mask-filling-with-roberta-and-huggingface-transformers-58eb9e7fb0c\n",
        "\n",
        "def get_prediction(sent):\n",
        "    token_ids = roberta_tokenizer.encode(sent, return_tensors='pt')\n",
        "    masked_position = (token_ids.squeeze() == roberta_tokenizer.mask_token_id).nonzero()\n",
        "    masked_pos = [mask.item() for mask in masked_position ]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = roberta_model(token_ids)\n",
        "\n",
        "    last_hidden_state = output[0].squeeze()\n",
        "\n",
        "    list_of_list =[]\n",
        "    for index,mask_index in enumerate(masked_pos):\n",
        "        words = []\n",
        "        while not words:\n",
        "            mask_hidden_state = last_hidden_state[mask_index]\n",
        "            idx = torch.topk(mask_hidden_state, k=5, dim=0)[1]\n",
        "\n",
        "            # Discard predicted word if it is blank or end token\n",
        "            for i in idx:\n",
        "                word = roberta_tokenizer.decode(i.item()).strip()\n",
        "                if (remove_punctuation(word) != \"\") and (word != '</s>'):\n",
        "                    words.append(word)\n",
        "        list_of_list.append(words)\n",
        "        print(f\"Mask {index+1} Guesses: {words}\")\n",
        "    \n",
        "    best_guess = \"\"\n",
        "    for j in list_of_list:\n",
        "        best_guess = best_guess+\" \"+j[0]\n",
        "        \n",
        "    return best_guess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp8L4cJwmoXP"
      },
      "source": [
        "## GPT-2 + RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "o2Rtm86GKwbg"
      },
      "outputs": [],
      "source": [
        "# Used to generate the 1st and 3rd lines of the limerick\n",
        "# these are full lines, without RoBERTa being used\n",
        "def get_line(prompt, inputs_len):\n",
        "    output = gpt2_pipeline(\n",
        "        prompt + \".\",\n",
        "        min_length=4,\n",
        "        max_length=inputs_len + 7,\n",
        "        clean_up_tokenization_spaces=True,\n",
        "        return_full_text=False\n",
        "    )\n",
        "    return remove_punctuation(output[0]['generated_text'])\n",
        "\n",
        "# Used to generate the 2nd, 4th and 5th lines\n",
        "# GPT-2 is used to generate starting few words of the lines\n",
        "# RoBERTa is then used to fill in the rest of the words until the end rhyme word\n",
        "def get_rhyming_line(prompt, rhyming_word, inputs_len):\n",
        "    output = gpt2_pipeline(\n",
        "        prompt + \".\",\n",
        "        min_length=4,\n",
        "        max_length=inputs_len + 3,\n",
        "        clean_up_tokenization_spaces=True,\n",
        "        return_full_text=False\n",
        "    )\n",
        "    gpt2_sentence = remove_punctuation(output[0]['generated_text'])\n",
        "    while len(gpt2_sentence) == 0:\n",
        "        output = gpt2_pipeline(\n",
        "            prompt + \".\",\n",
        "            min_length=4,\n",
        "            max_length=inputs_len + 3,\n",
        "            clean_up_tokenization_spaces=True,\n",
        "            return_full_text=False\n",
        "        )\n",
        "        gpt2_sentence = remove_punctuation(output[0]['generated_text'])\n",
        "    \n",
        "    print(f\"\\nGetting rhyming line starting with '{gpt2_sentence}' and ending with rhyming word '{rhyming_word}'\")\n",
        "    sentence = gpt2_sentence + \" ___ ___ ___ \" + rhyming_word\n",
        "    print(f\"Original Sentence: {sentence}\")\n",
        "    if sentence[-1] != \".\":\n",
        "        sentence = sentence.replace(\"___\",\"<mask>\") + \".\"\n",
        "    else:\n",
        "        sentence = sentence.replace(\"___\",\"<mask>\")\n",
        "    print(f\"Original Sentence replaced with mask: {sentence}\")\n",
        "    print(\"\\n\")\n",
        " \n",
        "    predicted_blanks = get_prediction(sentence)\n",
        "    print(f\"\\nBest guess for fill in the blanks: {predicted_blanks}\")\n",
        "    final_sentence = gpt2_sentence + predicted_blanks + \" \" + rhyming_word\n",
        "    print(f\"Final Sentence: {final_sentence}\")\n",
        "    return final_sentence\n",
        "\n",
        "# Used for the second method, Method B, of limerick generation\n",
        "# Uses GPT-2 to get information about the user's given topic \n",
        "def gpt2_summary(topic):\n",
        "    output = gpt2_pipeline(\n",
        "        f\"Here is some information about {topic}.\",\n",
        "        min_length=100,\n",
        "        max_length=300,\n",
        "        clean_up_tokenization_spaces=True,\n",
        "        return_full_text=False\n",
        "    )\n",
        "    return remove_punctuation(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Bqq_Zemsf3"
      },
      "source": [
        "## Limerick generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dDeTSyiisEJJ"
      },
      "outputs": [],
      "source": [
        "# Main logic for limerick generation is contained here\n",
        "def generate(topic, wiki=True):\n",
        "\n",
        "    # Search for the topic on Wikipedia and get an informational summary\n",
        "    if wiki:\n",
        "        try:\n",
        "            topic_search = wikipedia.search(topic, results=3)\n",
        "            print(f\"Wikipedia search results for {topic} are: {topic_search}\")\n",
        "            topic_summary = remove_punctuation(wikipedia.summary(topic_search[0], auto_suggest=False))\n",
        "        except wikipedia.DisambiguationError as e:\n",
        "            print(f\"Wikipedia returned a disambiguation error for {topic}. Selecting the first option {e.options[0]} instead.\")\n",
        "            page = e.options[0]\n",
        "            topic_summary = remove_punctuation(wikipedia.summary(page, auto_suggest=False))\n",
        "        except:\n",
        "            return(f\"Method A struggled to find information about {topic}, please try a different topic!\")\n",
        "\n",
        "    # Use GPT-2 to get info about the topic if the wiki parameter is false\n",
        "    else:\n",
        "        topic_summary = remove_punctuation(gpt2_summary(topic))\n",
        "\n",
        "    # Log info about the topic summary data\n",
        "    word_list = topic_summary.split()\n",
        "    topic_summary_len = len(topic_summary)\n",
        "    no_of_words = len(word_list)\n",
        "    inputs_len = get_inputs_length(topic_summary)\n",
        "    print(f\"Topic Summary: {topic_summary}\")\n",
        "    print(f\"Topic Summary Length: {topic_summary_len}\")\n",
        "    print(f\"No of Words in Summary: {no_of_words}\")\n",
        "    print(f\"Length of Input IDs: {inputs_len}\")         \n",
        "\n",
        "    # Generate the first line of the limerick\n",
        "    rhyming_words_125 = []\n",
        "    while len(rhyming_words_125) < 3 or valid_rhyme == False or len(first_line) == 0:\n",
        "        first_line = get_line(topic_summary, inputs_len)\n",
        "        if first_line:\n",
        "            end_word = remove_punctuation(first_line.split()[-1])\n",
        "            valid_rhyme = filter_rhymes(end_word)\n",
        "            if valid_rhyme:\n",
        "                print(f\"\\nFirst Line: {first_line}\")\n",
        "                rhyming_words_125 = list(get_rhymes(end_word, 3))\n",
        "                print(f\"Rhyming words for '{end_word}' are {rhyming_words_125}\")\n",
        "                limerick = first_line + \"\\n\"\n",
        "\n",
        "    # Generate the second line of the limerick\n",
        "    rhyming_word = random.choice(rhyming_words_125)\n",
        "    rhyming_words_125.remove(rhyming_word)\n",
        "    prompt = topic_summary + \" \" + first_line\n",
        "    inputs_len = get_inputs_length(prompt)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Length of prompt: {inputs_len}\")\n",
        "    second_line = get_rhyming_line(prompt, rhyming_word, inputs_len)\n",
        "    print(f\"\\nSecond Line: {second_line}\")\n",
        "    limerick += second_line + \"\\n\"\n",
        "\n",
        "    # Generate the third line of the limerick\n",
        "    rhyming_words_34 = []\n",
        "    prompt = prompt + \" \" + second_line\n",
        "    inputs_len = get_inputs_length(prompt)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Length of prompt: {inputs_len}\")\n",
        "    while len(rhyming_words_34) < 2 or valid_rhyme == False or len(third_line) == 0:\n",
        "        third_line = get_line(prompt, inputs_len)\n",
        "        if third_line:\n",
        "            print(f\"\\nThird Line: {third_line}\")\n",
        "            end_word = remove_punctuation(third_line.split()[-1])\n",
        "            valid_rhyme = filter_rhymes(end_word)\n",
        "            print(f\"Does '{end_word}' have valid rhymes: {valid_rhyme}\")\n",
        "            rhyming_words_34 = list(get_rhymes(end_word, 3))\n",
        "            print(f\"Rhyming words for '{end_word}' are {rhyming_words_34}\")\n",
        "            if valid_rhyme and len(rhyming_words_34) > 1:\n",
        "                limerick += third_line + \"\\n\"\n",
        "\n",
        "    # Generate the fourth line of the limerick\n",
        "    rhyming_word = random.choice(rhyming_words_34)\n",
        "    rhyming_words_34.remove(rhyming_word)\n",
        "    prompt = prompt + \" \" + third_line\n",
        "    inputs_len = get_inputs_length(prompt)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Length of prompt: {inputs_len}\")\n",
        "    fourth_line = get_rhyming_line(prompt, rhyming_word, inputs_len)\n",
        "    print(f\"\\nFourth Line: {fourth_line}\")\n",
        "    limerick += fourth_line + \"\\n\"\n",
        "\n",
        "    # Generate the fifth line of the limerick\n",
        "    rhyming_word = random.choice(rhyming_words_125)\n",
        "    rhyming_words_125.remove(rhyming_word)\n",
        "    prompt = prompt + \" \" + fourth_line\n",
        "    inputs_len = get_inputs_length(prompt)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Length of prompt: {inputs_len}\")\n",
        "    fifth_line = get_rhyming_line(prompt, rhyming_word, inputs_len)\n",
        "    print(f\"\\nFifth Line: {fifth_line}\")\n",
        "    limerick += fifth_line + \"\\n\"\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(limerick)\n",
        "\n",
        "    return limerick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TQEaAhJs9QsE"
      },
      "outputs": [],
      "source": [
        "# Helper function to generate two limericks via both methods to then compare\n",
        "def compare_summaries(topic):\n",
        "    wiki_limerick = generate(topic)\n",
        "    gpt2_limerick = generate(topic, wiki=False)\n",
        "\n",
        "    output1 = wiki_limerick\n",
        "    output2 = gpt2_limerick\n",
        "    print(output1 + \"\\n\" + output2)\n",
        "\n",
        "    return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "R0jKpWgAx-cd",
        "outputId": "eea77c46-4405-44a4-afab-f72b0bd2ee83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://59280.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f65088c4210>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://59280.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<fastapi.applications.FastAPI at 0x7f650bf7bf90>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://59280.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Use Gradio to create an interface, which can be hosted on HuggingFace spaces\n",
        "# https://huggingface.co/spaces/ansfarooq7/l4-project\n",
        "\n",
        "description = \"Generates limericks (five-line poems with a rhyme scheme of AABBA) using two different methods, please be patient as it can take up to a minute to generate both limericks.\"\n",
        "article = '<center><big><strong>Limerick Generation</strong></big></center>'\\\n",
        "        '<center><strong>By Ans Farooq</strong></center>'\\\n",
        "        '<center><small>Level 4 Individual Project</small></center>'\\\n",
        "        '<center><small>BSc Computing Science</small></center>'\\\n",
        "        '<center><small>University of Glasgow</small></center>'\\\n",
        "        '<strong>Description</strong><br>'\\\n",
        "        'Recent advances in natural language processing (NLP) have shown '\\\n",
        "        'incredible promise at generating human-quality language. Poetry '\\\n",
        "        'presents an additional challenge as it often relies on rhyme and '\\\n",
        "        'rhythm of language. Factoring these in presents an interesting '\\\n",
        "        'challenge to new deep learning-based methods. This text-generation '\\\n",
        "        'project examines the use of transformer-based deep learning methods '\\\n",
        "        'and the addition of constraints for length, rhyme and rhythm given '\\\n",
        "        'example words to seed a poem. This interface allows you to produce two '\\\n",
        "        'cohesive limericks automatically, using two different methods. The '\\\n",
        "        'results of this project are to be evaluated through human comparisons.'\n",
        "\n",
        "gr_input = gr.inputs.Textbox(label='Topic')\n",
        "gr_output1 = gr.outputs.Textbox(label='Method A')\n",
        "gr_output2 = gr.outputs.Textbox(label='Method B')\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=compare_summaries, \n",
        "    inputs=gr_input, \n",
        "    outputs=[gr_output1, gr_output2],\n",
        "    title=\"Text-generation with rhyme and rhythm\",\n",
        "    layout=\"horizontal\",\n",
        "    theme=\"peach\",\n",
        "    description=description,\n",
        "    article=article)\n",
        "interface.launch(debug=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "L4 Project.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}